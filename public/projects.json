[
  {
    "id": "deep-research-agent",
    "title": "DeepSearch-Agent",
    "description": "A Multi-step autonomous research agent. It takes a high-level user query, interactively refines the research scope, dynamically plans a report outline, gathers information from the web, and writes a comprehensive, cited report in Markdown",
    "details": {
      "summary": "A Multi-step autonomous research agent that takes a high-level user query, interactively refines the research scope, dynamically plans a report outline, gathers information from the web, and writes a comprehensive, cited report in Markdown. It uses Tavily API for web search/scraping and Gemini AI API for LLM.",
      "sections": [
        {
          "title": "Features",
          "list": [
            "Human-in-the-Loop: Starts by asking clarifying questions to narrow down the user's intent.",
            "Dynamic Outline Planning: Generates a structured report outline based on initial search results, then expands each section with key questions.",
            "Deep Research: Performs targeted, deep-dive searches for each section of the report.",
            "Retrieval-Augmented Generation (RAG): Chunks and embeds research content into a vector store (FAISS) to find the most relevant information for writing.",
            "Source Citation: Meticulously cites every factual statement, linking it back to the source URL.",
            "Context-Aware Writing: Keeps track of previously written sections to maintain flow and avoid repetition.",
            "PDF Export: Converts the final Markdown report into a high-quality, well-formatted PDF with a table of contents using Pandoc and LaTeX."
          ],
          "isOrdered": false
        },
        {
          "title": "How it Works",
          "list": [
            "Initial Topic: You provide a research topic.",
            "Clarification: The agent asks clarifying questions to narrow down the scope and understand your requirements.",
            "Research & Report Generation: Based on your answers, the agent conducts research and generates a report section by section. You can see the progress in the UI.",
            "Download Report: Once the report is complete, a \"Download Report as PDF\" button will appear. Click it to download the report."
          ],
          "isOrdered": true
        }
      ]
    },
    "links": {
      "github": "https://github.com/rajput-musa/DeepResearch-Agent",
      "live": "https://huggingface.co/spaces/MusaR/Mini-DeepResearch-Agent"
    },
    "tags": ["Python", "Agent", "AI", "RAG", "DeepSearch", "Gemini", "Tavily"]
  },
  {
    "id": "nlp-rag-world-news",
    "title": "NLP RAG on 30,000 World News Articles",
    "description": "A RAG pipeline built on the world news dataset, featuring hybrid retrieval and cross-encoder reranking.",
    "details": {
      "summary": "This project implements a complete Retrieval-Augmented Generation (RAG) pipeline from scratch to answer queries based on a dataset of 30,000 world news articles. Unlike typical RAG systems that rely on high-level frameworks, this project uses low-level libraries like PyTorch, Transformers, and FAISS to showcase the core mechanics and allow maximum control over the architecture.",
      "sections": [
        {
          "title": "Key Features",
          "list": [
            "Custom From-Scratch RAG Implementation",
            "Hybrid Retrieval using BM25 for keywords and FAISS for semantics",
            "Cross-Encoder Reranking for contextual relevance",
            "Optimized for deployment on Hugging Face Spaces"
          ],
          "isOrdered": false
        },
        {
          "title": "Core Technologies",
          "list": [
            "LLM: Microsoft Phi-3",
            "Embeddings: multi-qa-MiniLM-L6-cos-v1",
            "Reranker: cross-encoder/ms-marco-MiniLM-L-6-v2",
            "Core Tools: PyTorch, Transformers, Gradio, FAISS, Pandas",
            "Platform: Hugging Face Spaces"
          ],
          "isOrdered": false
        }
      ]
    },
    "links": {
      "github": "https://github.com/rajput-musa/NLP-RAG-World-News",
      "live": "https://huggingface.co/spaces/MusaR/NLP-RAG-world-news"
    },
    "tags": ["PyTorch", "Transformers", "Gradio", "FAISS", "Python", "RAG", "AI", "LLM"]
  },
  {
    "id": "brain-tumor-segmentation",
    "title": "Brain Tumor Segmentation using Residual U-Net",
    "description": "A deep learning model for precise, pixel-level segmentation of brain tumors from MRI scans, achieving a Dice Score of 0.9279.",
    "details": {
      "summary": "This project involved developing a deep learning model for precise, pixel-level segmentation of brain tumors from MRI scans. A custom U-Net architecture incorporating Residual Blocks was engineered from scratch to improve gradient flow and training stability.",
      "sections": [
        {
          "title": "Key Achievements",
          "list": [
            "Engineered a custom U-Net with Residual Blocks from scratch.",
            "Achieved a Dice Score of 0.9279 and an IoU of 0.8657 on the BR35H dataset.",
            "Implemented a full preprocessing pipeline including median filtering and unsharp masking.",
            "Validated model performance using domain-specific metrics (Dice, IoU)."
          ],
          "isOrdered": false
        },
        {
          "title": "Technologies Used",
          "list": [
            "Python",
            "TensorFlow",
            "Keras",
            "OpenCV",
            "Scikit-learn"
          ],
          "isOrdered": false
        }
      ]
    },
    "links": {},
    "tags": ["Python", "TensorFlow", "Keras", "OpenCV", "Deep Learning", "AI", "Computer Vision", "Medical Imaging"]
  },
  {
    "id": "rag-chatbot",
    "title": "RAG Document Chatbot",
    "description": "An interactive RAG chatbot that answers questions from documents with semantic search, re-ranking, and LLMs for accurate, source-backed answers.",
    "details": {
      "summary": "An interactive Retrieval-Augmented Generation (RAG) chatbot that answers questions based on any document corpus. It combines semantic search, re-ranking, and large language models (LLMs) to deliver accurate, context-aware, and source-backed answers.",
      "sections": [
        {
          "title": "How It Works",
          "list": [
            "User submits a question.",
            "The question is embedded using all-MiniLM-L6-v2.",
            "Pinecone retrieves semantically relevant document chunks.",
            "Cohere's Rerank API refines the context ordering.",
            "Groq's Llama 3 70B generates a final answer using the top-ranked context.",
            "The chatbot displays the answer along with the referenced sources."
          ],
          "isOrdered": true
        },
        {
          "title": "Core Technologies",
          "list": [
            "Vector DB: Pinecone",
            "LLM: Llama 3 70B via Groq API",
            "Re-ranking: Cohere Rerank",
            "Embeddings: all-MiniLM-L6-v2",
            "Frontend: Streamlit",
            "Deployment: Hugging Face Spaces via Docker"
          ],
          "isOrdered": false
        }
      ]
    },
    "links": {
      "github": "https://github.com/rajput-musa/rag-chatbot",
      "live": "https://huggingface.co/spaces/MusaR/rag-chatbot"
    },
    "tags": ["Python", "Pinecone", "LLM", "Cohere", "Streamlit", "Docker", "RAG", "AI"]
  },
  {
    "id": "local-rag-chatbot",
    "title": "RAG Chatbot for Multiple PDFs",
    "description": "An advanced Retrieval-Augmented Generation (RAG) chatbot to converse with multiple PDF documents, running a local language model (Phi-3) on your machine.",
    "details": {
      "summary": "This project is an advanced Retrieval-Augmented Generation (RAG) chatbot that allows you to have conversations about the content of multiple PDF documents. It leverages a powerful local language model (Phi-3), a cloud-based vector database (Pinecone), and a user-friendly web interface built with Streamlit.",
      "sections": [
        {
          "title": "Features",
          "list": [
            "Multi-PDF Querying: Ingests and processes multiple PDF files from a local directory.",
            "High-Performance RAG Pipeline: Uses a pipeline with langchain for efficient and relevant document retrieval.",
            "Local LLM: Runs the powerful microsoft/Phi-3-mini-4k-instruct model locally using llama-cpp-python.",
            "Cloud Vector Store: Utilizes Pinecone for a scalable and persistent vector database.",
            "Interactive UI: A clean and intuitive chat interface powered by Streamlit."
          ],
          "isOrdered": false
        },
        {
          "title": "Tech Stack",
          "list": [
            "Orchestration: LangChain",
            "LLM: Microsoft Phi-3",
            "Vector Database: Pinecone",
            "Embeddings: all-MiniLM-L6-v2",
            "UI: Streamlit"
          ],
          "isOrdered": false
        }
      ]
    },
    "links": {
      "github": "https://github.com/rajput-musa/local-RAG-chatbot"
    },
    "tags": ["Python", "LangChain", "LLM", "RAG", "Streamlit", "AI"]
  },
  {
    "id": "real-time-cv",
    "title": "Real-Time Object Detection & CV Projects",
    "description": "A collection of real-time computer vision systems for specific detection tasks using YOLOv8, including drowsiness detection and automated attendance.",
    "details": {
      "summary": "This project consolidates practical computer vision work, focusing on developing and fine-tuning various real-time systems. Key applications include a drowsiness detector, an automated attendance system using face recognition, and a custom object detector for Shemagh apparel.",
      "sections": [
        {
          "title": "Key Features",
          "list": [
            "Utilized YOLOv8 for high-performance, real-time object detection.",
            "Managed the full CV lifecycle: data collection, annotation, model fine-tuning, and evaluation (mAP, FPS).",
            "Built practical applications for drowsiness detection, automated attendance, and custom object recognition."
          ],
          "isOrdered": false
        },
        {
          "title": "Technologies Used",
          "list": [
            "Python",
            "PyTorch",
            "YOLOv8",
            "OpenCV"
          ],
          "isOrdered": false
        }
      ]
    },
    "links": {},
    "tags": ["Python", "PyTorch", "YOLOv8", "OpenCV", "AI", "Computer Vision"]
  },
  {
    "id": "cpu-scheduling-algorithms",
    "title": "CPU Scheduling Algorithms",
    "description": "Implementation and visualization of various CPU scheduling algorithms like Banker's, SJF, FCFS, Round Robin, and Priority, calculating performance metrics.",
    "details": {
      "summary": "This repository implements various CPU scheduling algorithms commonly used in operating systems. The main.py file includes the implementation of the following algorithms along with their Gantt chart visualization. Also, it calculates the waiting time (WT), turnaround time (TAT), and average waiting (AWT) and turnaround time (ATAT) for each algorithm.",
      "sections": [
        {
          "title": "Implemented Algorithms",
          "list": [
            "Banker's Algorithm",
            "Shortest Job First (SJF) (Preemptive & Non-Preemptive)",
            "First-Come First-Served (FCFS)",
            "Round Robin",
            "Priority (Preemptive & Non-Preemptive)"
          ],
          "isOrdered": false
        }
      ]
    },
    "links": {
      "github": "https://github.com/rajput-musa/CPUSchedulingAlgorithms"
    },
    "tags": ["Python", "Operating Systems", "Algorithms"]
  },
  {
    "id": "aes-fpga-accelerator",
    "title": "AES Hardware Accelerator on FPGA (FYP)",
    "description": "A high-throughput, pipelined hardware core for AES encryption and decryption implemented on an Artix-7 FPGA, achieving 6.2 Gb/s.",
    "details": {
      "summary": "This Final Year Project involved designing, implementing, and optimizing a high-throughput hardware core for AES encryption and decryption on an FPGA. The design features a pipelined architecture, optimized S-box implementations, and countermeasures against side-channel attacks.",
      "sections": [
        {
          "title": "Key Achievements",
          "list": [
            "Designed a pipelined architecture achieving 6.2 Gb/s throughput.",
            "Implemented optimized S-box designs and countermeasures against side-channel attacks.",
            "Performed rigorous verification with simulation test benches in Vivado and iSim.",
            "Analyzed and optimized hardware resource utilization (LUTs, flip-flops) on the Artix-7 FPGA."
          ],
          "isOrdered": false
        },
        {
          "title": "Technologies Used",
          "list": [
            "Verilog",
            "Vivado",
            "Xilinx ISE",
            "Artix-7 FPGA"
          ],
          "isOrdered": false
        }
      ]
    },
    "links": {},
    "tags": ["Verilog", "FPGA", "Hardware", "Cryptography", "AES", "Vivado"]
  },
  {
    "id": "digital-steganography",
    "title": "Digital Steganography",
    "description": "A Java application to embed and extract secret text messages within digital images using the Least Significant Bit (LSB) steganography technique.",
    "details": {
      "summary": "Digital Steganography is a Java application that enables the embedding and extraction of secret messages within digital images. Steganography is the practice of concealing information within other non-secret data to maintain the confidentiality of the message. This project utilizes the technique of LSB (Least Significant Bit) steganography to embed text messages within image files.",
      "sections": [
        {
          "title": "Features",
          "list": [
            "Embed a secret message within an image file.",
            "Extract a secret message from an image file.",
            "Supports various image formats such as JPEG, PNG, BMP, etc.",
            "User-friendly interface for easy interaction.",
            "Compatible with Java SE platform."
          ],
          "isOrdered": false
        },
        {
          "title": "Group Members",
          "list": [
            "Moosa Qaisar (21-CP-67)",
            "Aazib Majeed (21-CP-01)"
          ],
          "isOrdered": false
        }
      ]
    },
    "links": {
      "github": "https://github.com/rajput-musa/DigitalSteganography"
    },
    "tags": ["Java", "Steganography", "Security", "Image Processing"]
  }
] 